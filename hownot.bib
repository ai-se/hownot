@article{Menzies2010,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ay≈üe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}

@article{Menzies2013,
abstract = {Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.},
author = {Menzies, Tim and Butcher, Andrew and Cok, David and Marcus, Andrian and Layman, Lucas and Shull, Forrest and Turhan, Burak and Zimmermann, Thomas},
doi = {10.1109/TSE.2012.83},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Data mining,clustering,defect prediction,effort estimation},
number = {6},
pages = {822--834},
title = {{Local versus global lessons for defect prediction and effort estimation}},
volume = {39},
year = {2013}
}


@mastersthesis{div14,
  title="Exploring Essential content of Defect Prediction 
         and Effort Estimation through Data Reduction",
  year=2014,
  author="Divya Ganesan",
  school="Computer Science, West Virginia University"
 }

@book{fastmap,
  title={FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
  author={Faloutsos, Christos and Lin, King-Ip},
  volume={24},
  number={2},
  year={1995},
  publisher={ACM}
}
@ARTICLE{6600685, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}
@inproceedings{kocaguneli2010use,
  title={When to use data from other projects for effort estimation},
  author={Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
  booktitle={Proceedings of the IEEE/ACM international conference on Automated software engineering},
  pages={321--324},
  year={2010},
  organization={ACM}
}
@article{HOW,
author = {Krishna, Rahul and Menzies, Tim and Shen, Xipeng and Marcus, Andrian},
file = {:Users/rkrsn/Documents/Mendeley Desktop/Krishna et al. - Learning Actionable Analytics ( with applications for reducing defects and reducing runtimes ).pdf:pdf},
title = {{Learning Actionable Analytics ( with applications for reducing defects and reducing runtimes )}}
}

@inproceedings{jureczko10,
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {9:1----9:10},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
year = {2010}
}
@article{mittas13,
  author =	{Nikolaos Mittas and Lefteris Angelis},
  title =	{Ranking and Clustering Software Cost Estimation
                  Models through a Multiple Comparisons Algorithm},
  journal =	{IEEE Trans. Software Eng.},
  volume =	39,
  number =	4,
  year =	2013,
  pages =	{537-551},
}